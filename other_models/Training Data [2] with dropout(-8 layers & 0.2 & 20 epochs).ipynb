{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847fa3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.optimizer_v1 import SGD\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d732a1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCT images of 1024 x 1024 pixels with 1 channel\n",
    "IMG_ROWS=224; IMG_COLS=224; IMG_CHANNELS=1\n",
    "IMAGE_SIZE = [IMG_ROWS, IMG_COLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHICH_MODEL = 'DenseNet121'\n",
    "\n",
    "if WHICH_MODEL == 'VGG16':\n",
    "    from keras.applications.vgg16 import VGG16\n",
    "    from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "    # for RGB channel use [3], for black and white use one channel [1], and IMAGE_SIZE + [3] = [224, 224, 3]\n",
    "    orig_model = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "    LEARN_RATE = 0.0001\n",
    "    OCT_MODEL_NAME = 'VGG16_oct_minipigs.h5'\n",
    "\n",
    "elif WHICH_MODEL == 'VGG19':\n",
    "    from keras.applications.vgg19 import VGG19\n",
    "    from keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "    # for RGB channel use [3], for black and white use one channel [1]\n",
    "    orig_model = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "    LEARN_RATE = 0.0001\n",
    "    OCT_MODEL_NAME = 'VGG19_oct_minipigs.h5'\n",
    "\n",
    "elif WHICH_MODEL == 'ResNet50':\n",
    "    from keras.applications.resnet50 import ResNet50\n",
    "    from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "    orig_model = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "    LEARN_RATE = 0.001\n",
    "    OCT_MODEL_NAME = 'ResNet50_oct_minipigs.h5'\n",
    "\n",
    "elif WHICH_MODEL == 'InceptionV3':\n",
    "    from keras.applications.inception_v3 import InceptionV3\n",
    "    from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "    orig_model = InceptionV3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "    LEARN_RATE = 0.0001\n",
    "    OCT_MODEL_NAME = 'InceptionV3_oct_minipigs.h5'\n",
    "\n",
    "elif WHICH_MODEL == 'DenseNet121':\n",
    "    from keras.applications.densenet import DenseNet121\n",
    "    from keras.applications.densenet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28744830",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_model = DenseNet121(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "LEARN_RATE = 0.0001\n",
    "OCT_MODEL_NAME = 'DenseNet121_oct_minipigs.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da72cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd9b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to TRAINING dataset of the OCT images\n",
    "TRAIN_PATH = 'C:\\\\Users\\\\Ali\\Documents\\\\minipigs_images\\\\Split_Data\\\\train'\n",
    "\n",
    "# path to VALIDATE dataset of the OCT images\n",
    "VALID_PATH = 'C:\\\\Users\\\\Ali\\\\Documents\\\\minipigs_images\\\\Split_Data\\\\val'\n",
    "\n",
    "# path to TESTING dataset of the OCT images\n",
    "TEST_PATH = 'C:\\\\Users\\\\Ali\\\\Documents\\\\minipigs_images\\\\Split_Data\\\\test'\n",
    "\n",
    "DATASET = 'Minipigs'\n",
    "\n",
    "CLASS_MODE = 'categorical'   # binary, categorical\n",
    "\n",
    "NUMBER_OF_CLASSES = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adam = Adam(learning_rate=LEARN_RATE)\n",
    "#adam = Adam(learning_rate=LEARN_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='Adam', decay=LEARN_RATE/EPOCHS)\n",
    "\n",
    "#sgd = SGD(learning_rate=LEARN_RATE)\n",
    "\n",
    "OPTIMISATION = adam  # SGD\n",
    "\n",
    "# no need to train the weights again\n",
    "for layer in orig_model.layers[:-8]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to retrieve the number of classes\n",
    "folders = glob(TRAIN_PATH + '/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f635812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more layers could be added to the model\n",
    "x = Flatten()(orig_model.output)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=orig_model.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93898734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimisation method to use\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=OPTIMISATION,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b908596",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, rotation_range=350, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.15, zoom_range=0.1,\n",
    "    channel_shift_range=10., horizontal_flip=True, fill_mode='constant'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d2a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size=(IMG_ROWS, IMG_COLS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "#    seed=42,\n",
    "#    color_mode=COLOUR_MODE,\n",
    "    class_mode=CLASS_MODE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f289ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, rotation_range=350, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.15, zoom_range=0.1,\n",
    "    channel_shift_range=10., horizontal_flip=True, fill_mode='constant'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b5b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set = valid_datagen.flow_from_directory(\n",
    "    VALID_PATH,\n",
    "    target_size=(IMG_ROWS, IMG_COLS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "#    seed=42,\n",
    "#    color_mode=COLOUR_MODE,\n",
    "    class_mode=CLASS_MODE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff171025",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    target_size=(IMG_ROWS, IMG_COLS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "#    seed=42,\n",
    "#    color_mode=COLOUR_MODE,\n",
    "    class_mode=CLASS_MODE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e76bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "history = model.fit(\n",
    "    training_set,\n",
    "    validation_data=valid_set,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=len(training_set),\n",
    "#    validation_split=0.1\n",
    "    validation_steps=len(valid_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd5a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "acc_title = \"{} - Model Accuracy for the {} Dataset\".format(WHICH_MODEL, DATASET)\n",
    "plt.title(acc_title)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.grid(True)\n",
    "plt.legend(['Train Category Accuracy', 'Validation Category Accuracy'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88746944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "loss_title = \"{} - Loss Rate for the {} Dataset\".format(WHICH_MODEL, DATASET)\n",
    "plt.title(loss_title)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.grid(True)\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a7ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(training_set, steps=16)\n",
    "valid_loss, valid_acc = model.evaluate(valid_set, steps=16)\n",
    "\n",
    "print('\\nLearn Rate =', LEARN_RATE, ', Epochs =', EPOCHS, ', Training Folder =', TRAIN_PATH)\n",
    "\n",
    "print('Validation Folder =', VALID_PATH, ', Test Folder =', TEST_PATH)\n",
    "\n",
    "print('\\nTraining: %.3f, Validation: %.3f' % (train_acc, valid_acc))\n",
    "\n",
    "print('\\nThe processing of Convolutional Neural Networks with Transfer Learning for', WHICH_MODEL, 'succeed.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e6070",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_set, steps=16)\n",
    "print(\"\\nTest loss and accuracy are:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed6752",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_-8layers_0.2dropout_20epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0103221b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
