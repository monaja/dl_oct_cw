{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847fa3fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SGD\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Flatten, Dropout\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\__init__.py:41\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_six\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\__init__.py:49\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# from tensorflow.python import keras\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column_lib \u001b[38;5;28;01mas\u001b[39;00m feature_column\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# from tensorflow.python.layers import layers\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_lib.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence_feature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:147\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m sparse_tensor_lib\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n\u001b[1;32m--> 147\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_ops\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_ops\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\layers\\base.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy_tf_layers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[0;32m     22\u001b[0m InputSpec \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mInputSpec\n\u001b[0;32m     24\u001b[0m keras_style_scope \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mkeras_style_scope\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\models.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics \u001b[38;5;28;01mas\u001b[39;00m metrics_module\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer_v1\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:846\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:941\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1040\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.optimizer_v1 import SGD\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d732a1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCT images of 1024 x 1024 pixels with 1 channel\n",
    "IMG_ROWS=224; IMG_COLS=224; IMG_CHANNELS=1\n",
    "IMAGE_SIZE = [IMG_ROWS, IMG_COLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHICH_MODEL = 'DenseNet121'\n",
    "\n",
    "if WHICH_MODEL == 'VGG16':\n",
    "    from keras.applications.vgg16 import VGG16\n",
    "    from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "    # for RGB channel use [3], for black and white use one channel [1], and IMAGE_SIZE + [3] = [224, 224, 3]\n",
    "    orig_model = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "    LEARN_RATE = 0.0001\n",
    "    OCT_MODEL_NAME = 'VGG16_oct_minipigs.h5'\n",
    "\n",
    "elif WHICH_MODEL == 'VGG19':\n",
    "    from keras.applications.vgg19 import VGG19\n",
    "    from keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "    # for RGB channel use [3], for black and white use one channel [1]\n",
    "    orig_model = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "    LEARN_RATE = 0.0001\n",
    "    OCT_MODEL_NAME = 'VGG19_oct_minipigs.h5'\n",
    "\n",
    "elif WHICH_MODEL == 'ResNet50':\n",
    "    from keras.applications.resnet50 import ResNet50\n",
    "    from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "    orig_model = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "    LEARN_RATE = 0.001\n",
    "    OCT_MODEL_NAME = 'ResNet50_oct_minipigs.h5'\n",
    "\n",
    "elif WHICH_MODEL == 'InceptionV3':\n",
    "    from keras.applications.inception_v3 import InceptionV3\n",
    "    from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "    orig_model = InceptionV3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "    LEARN_RATE = 0.0001\n",
    "    OCT_MODEL_NAME = 'InceptionV3_oct_minipigs.h5'\n",
    "\n",
    "elif WHICH_MODEL == 'DenseNet121':\n",
    "    from keras.applications.densenet import DenseNet121\n",
    "    from keras.applications.densenet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28744830",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_model = DenseNet121(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "LEARN_RATE = 0.0001\n",
    "OCT_MODEL_NAME = 'DenseNet121_oct_minipigs.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da72cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd9b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to TRAINING dataset of the OCT images\n",
    "TRAIN_PATH = 'C:\\\\Users\\\\Ali\\Documents\\\\minipigs_images\\\\Split_Data\\\\train'\n",
    "\n",
    "# path to VALIDATE dataset of the OCT images\n",
    "VALID_PATH = 'C:\\\\Users\\\\Ali\\\\Documents\\\\minipigs_images\\\\Split_Data\\\\val'\n",
    "\n",
    "# path to TESTING dataset of the OCT images\n",
    "TEST_PATH = 'C:\\\\Users\\\\Ali\\\\Documents\\\\minipigs_images\\\\Split_Data\\\\test'\n",
    "\n",
    "DATASET = 'Minipigs'\n",
    "\n",
    "CLASS_MODE = 'categorical'   # binary, categorical\n",
    "\n",
    "NUMBER_OF_CLASSES = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adam = Adam(learning_rate=LEARN_RATE)\n",
    "#adam = Adam(learning_rate=LEARN_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='Adam', decay=LEARN_RATE/EPOCHS)\n",
    "\n",
    "#sgd = SGD(learning_rate=LEARN_RATE)\n",
    "\n",
    "OPTIMISATION = adam  # SGD\n",
    "\n",
    "# no need to train the weights again\n",
    "for layer in orig_model.layers[:-15]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to retrieve the number of classes\n",
    "folders = glob(TRAIN_PATH + '/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f635812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more layers could be added to the model\n",
    "x = Flatten()(orig_model.output)\n",
    "\n",
    "\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=orig_model.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93898734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimisation method to use\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=OPTIMISATION,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b908596",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, rotation_range=350, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.15, zoom_range=0.1,\n",
    "    channel_shift_range=10., horizontal_flip=True, fill_mode='constant'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d2a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size=(IMG_ROWS, IMG_COLS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "#    seed=42,\n",
    "#    color_mode=COLOUR_MODE,\n",
    "    class_mode=CLASS_MODE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f289ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, rotation_range=350, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.15, zoom_range=0.1,\n",
    "    channel_shift_range=10., horizontal_flip=True, fill_mode='constant'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b5b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set = valid_datagen.flow_from_directory(\n",
    "    VALID_PATH,\n",
    "    target_size=(IMG_ROWS, IMG_COLS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "#    seed=42,\n",
    "#    color_mode=COLOUR_MODE,\n",
    "    class_mode=CLASS_MODE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff171025",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    target_size=(IMG_ROWS, IMG_COLS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "#    seed=42,\n",
    "#    color_mode=COLOUR_MODE,\n",
    "    class_mode=CLASS_MODE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e76bb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "history = model.fit(\n",
    "    training_set,\n",
    "    validation_data=valid_set,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=len(training_set),\n",
    "#    validation_split=0.1\n",
    "    validation_steps=len(valid_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd5a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "acc_title = \"{} - Model Accuracy for the {} Dataset\".format(WHICH_MODEL, DATASET)\n",
    "plt.title(acc_title)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.grid(True)\n",
    "plt.legend(['Train Category Accuracy', 'Validation Category Accuracy'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88746944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "loss_title = \"{} - Loss Rate for the {} Dataset\".format(WHICH_MODEL, DATASET)\n",
    "plt.title(loss_title)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.grid(True)\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a7ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(training_set, steps=16)\n",
    "valid_loss, valid_acc = model.evaluate(valid_set, steps=16)\n",
    "\n",
    "print('\\nLearn Rate =', LEARN_RATE, ', Epochs =', EPOCHS, ', Training Folder =', TRAIN_PATH)\n",
    "\n",
    "print('Validation Folder =', VALID_PATH, ', Test Folder =', TEST_PATH)\n",
    "\n",
    "print('\\nTraining: %.3f, Validation: %.3f' % (train_acc, valid_acc))\n",
    "\n",
    "print('\\nThe processing of Convolutional Neural Networks with Transfer Learning for', WHICH_MODEL, 'succeed.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e6070",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_set, steps=16)\n",
    "print(\"\\nTest loss and accuracy are:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed6752",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_-15layers_100epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea549ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_predictions = model.predict(test_set)\n",
    "print('\\nPredictions:\\n')\n",
    "print(cnn_predictions)\n",
    "\n",
    "cnn_predictions_max = cnn_predictions.argmax(axis=1)\n",
    "print('\\nPredictions argmax(axis=1):\\n')\n",
    "print(cnn_predictions_max)\n",
    "\n",
    "print(test_set.labels)\n",
    "\n",
    "print('\\nTesting execution ended.\\n')\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "label = ['TCFA', 'FCA', 'PIT', 'normal', 'IT']\n",
    "#Ypred = np.argmax(cnn_predictions, axis=1)\n",
    "#Ytrue = np.argmax(test_set.labels, axis=0)\n",
    "\n",
    "cm = confusion_matrix(test_set.labels, cnn_predictions_max)\n",
    "plt.figure(figsize=(12, 12))\n",
    "ax = sns.heatmap(cm, cmap=\"rocket_r\", fmt=\".01f\",annot_kws={'size':16}, annot=True, square=True, xticklabels=label, yticklabels=label)\n",
    "ax.set_ylabel('Actual', fontsize=20)\n",
    "ax.set_xlabel('Predicted', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd9d13b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
